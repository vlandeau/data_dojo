{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](house_prices.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import Imputer\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"house_sales_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrait valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_dropped_na = None #TODO: enlever toutes les colonnes contenant des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dropped_na.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conserver seulement les colonnes numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_dropped_na.dtypes.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "df_numeric = None #TODO: sélectionner seulement les colonnes dont le type est numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_numeric.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlations = df_numeric.corr()\n",
    "most_correlated_features = correlations[\"SalePrice\"].sort_values(ascending=False)[:15]\n",
    "most_correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlations_most_correlated_features = df_numeric[most_correlated_features.index].corr()\n",
    "sns.heatmap(correlations_most_correlated_features, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=df_numeric.OverallQual, y=df_numeric.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.regplot(x=df_numeric.GrLivArea, y=df_numeric.SalePrice, color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_numeric[most_correlated_features.index[:8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premier modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cible et variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = \"SalePrice\"\n",
    "y = df_numeric[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df_numeric.drop(target, axis=1)\n",
    "features = x.columns.tolist()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](training_test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size_ratio = 0.2\n",
    "random_state = 123\n",
    "x_train, x_test, y_train, y_test = (None, None, None, None)\n",
    "#TODO: créer les ensembles d'entraînement et de test,\n",
    "#avec 80% de données d'entraînement et 20% de données de test\n",
    "#Indice: chercher une fonction qui fait ça dans scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeRegressor(max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: entraîner le modèle sur les données d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions sur l'ensemble d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_train = tree_model.predict(x_train)\n",
    "mean_absolute_error(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](r2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2_score(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_vs_realite_train = pd.DataFrame({\"predictions sur ensemble d'entrainement\": predictions_train,\n",
    "                                           \"valeurs ensemble d'entrainement\": y_train})\n",
    "predictions_vs_realite_train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_vs_realite_train.plot.scatter(x=\"predictions sur ensemble d'entrainement\", y=\"valeurs ensemble d'entrainement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = None # TODO: faire des prédictions sur les données de test\n",
    "r2_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_vs_realite = pd.DataFrame({\"predictions sur ensemble de test\": predictions,\n",
    "                                       \"valeurs ensemble de test\": y_test})\n",
    "predictions_vs_realite.plot.scatter(x=\"predictions sur ensemble de test\", y=\"valeurs ensemble de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jetons un oeil à l'arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot_data_tree = export_graphviz(tree_model, out_file=None, \n",
    "                         feature_names=features,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True) \n",
    "graphviz.Source(dot_data_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche des meilleurs paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![titile](training_and_test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_training, x_val, y_training, y_val = train_test_split(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_grid = {\"max_depth\": [None] + list(range(2, 12)), \n",
    "               \"min_samples_split\": list(range(2, 20))}\n",
    "\n",
    "# Créons la liste de toutes les combinaisons possibles de paramètres\n",
    "params_combinations_tuple_list = product(*(params_grid[key] for key in params_grid))\n",
    "params_combinations_dict_list = [{\"max_depth\": l[0], \n",
    "                                 \"min_samples_split\": l[1]} for l in\n",
    "                                params_combinations_tuple_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(params):\n",
    "    tree = DecisionTreeRegressor(**params)\n",
    "    #TODO: retourner le score R2 sur l'ensemble de validation, \n",
    "    # après entraînement sur l'ensemble d'entraînement\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pour chaque combinaison de paramètre, entraînons un arbre\n",
    "# et calculons son score sur l'ensemble de validation\n",
    "scores = [get_score(param_combination) \n",
    "          for param_combination in params_combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_score = max(scores)\n",
    "print(\"Score du meilleur modèle: %s\" % max_score)\n",
    "best_score_index = scores.index(max_score)\n",
    "best_params = params_combinations[best_score_index]\n",
    "best_tree = DecisionTreeRegressor(**best_params).fit(x_train, y_train)\n",
    "print(\"Score du meilleur modèle sur l'ensemble de test: %s\" % best_tree.score(x_test, y_test))\n",
    "\n",
    "print(\"Meilleurs paramètres: %s\" % best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_best_tree_vs_realite = pd.DataFrame({\"predictions sur ensemble de test\": best_tree.predict(x_test),\n",
    "                                       \"valeurs ensemble de test\": y_test})\n",
    "predictions_best_tree_vs_realite.plot.scatter(x=\"predictions sur ensemble de test\", y=\"valeurs ensemble de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](kfolds.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cross_val_score(params):\n",
    "    scores = []\n",
    "    x_train_matrix = x_train.as_matrix()\n",
    "    y_train_matrix = y_train.as_matrix()\n",
    "    # Créons six sous-ensembles (folds) de taille égale\n",
    "    kfold = KFold(n_splits=6)\n",
    "    # Et récupérons tous les ensembles d'entraînement et de validation possibles\n",
    "    for train_indices, val_indices in kfold.split(x_train_matrix):\n",
    "        x_train_k = x_train_matrix[train_indices, :]\n",
    "        y_train_k = y_train_matrix[train_indices]\n",
    "        x_val_k = x_train_matrix[val_indices, :]\n",
    "        y_val_k = y_train_matrix[val_indices]\n",
    "        #TODO: ajouter le score du modèle entraîné sur le sous-ensemble d'entraînement,\n",
    "        #appliqué sur le sous-ensemble de validation, à la liste des scores\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_cross_val_score(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recalculons les scores de chacune des combinaisons de paramètres\n",
    "cv_scores = [get_cross_val_score(param_combination)\n",
    "             for param_combination in params_combinations_dict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_score_cv = max(cv_scores)\n",
    "print(\"Score du meilleur modèle: %s\" % max_score_cv)\n",
    "best_score_index_cv = cv_scores.index(max_score_cv)\n",
    "best_params_cv = params_combinations_dict_list[best_score_index_cv]\n",
    "best_tree_cv = DecisionTreeRegressor(**best_params_cv).fit(x_train, y_train)\n",
    "print(\"Score du meilleur modèle sur l'ensemble de test: %s\" % best_tree_cv.score(x_test, y_test))\n",
    "\n",
    "print(\"Meilleurs paramètres: %s\" % best_params_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_vs_realite_cv = pd.DataFrame({\"predictions sur ensemble de test\": best_tree.predict(x_test),\n",
    "                                       \"valeurs ensemble de test\": y_test})\n",
    "predictions_best_tree_vs_realite.plot.scatter(x=\"predictions sur ensemble de test\", y=\"valeurs ensemble de test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(best_tree_cv, out_file=None, \n",
    "                         feature_names=features,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True) \n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compromis biais variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bootstrap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "sample_size = 1000\n",
    "pool_size = x_train.shape[0]\n",
    "\n",
    "def get_bootstrap_sample(pool_size=pool_size, sample_size=sample_size):\n",
    "    return np.random.choice(range(pool_size), size=sample_size, replace=True)\n",
    "\n",
    "# Créons une liste d'indices d'échantillons \"bootstrap\" sur l'ensemble d'entraînement\n",
    "samples = [get_bootstrap_sample() for _ in range(n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_individual_tree(sample, max_depth=2):\n",
    "    x_train_sample = x_train.as_matrix()[sample, :]\n",
    "    y_train_sample = y_train.as_matrix()[sample]\n",
    "    tree_sample = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    return tree_sample.fit(x_train_sample, y_train_sample)\n",
    "\n",
    "mean_bias, mean_variance = [], []\n",
    "scores_one_tree = []\n",
    "max_depths = range(1, 25, 2)\n",
    "# Pour différentes valeurs de profondeur possibles...\n",
    "for depth in max_depths:\n",
    "    # On va entraîner des arbres de décision, un par échantillon bootstrap\n",
    "    tree_samples = [train_individual_tree(sample, depth) for sample in samples]\n",
    "    predictions_tree_samples = None \n",
    "    #TODO: renseigner les prédictions de chacun des arbres sur x_test\n",
    "    \n",
    "    # On calcule les taux d'erreur de chacun des arbres...\n",
    "    error_rates = np.concatenate([((x - y_test) / y_test).values.reshape(len(y_test), 1) \n",
    "                                for x in predictions_tree_samples],\n",
    "                              axis=1)\n",
    "    # Et on en déduit un taux d'erreur moyen, ou bias\n",
    "    mean_bias.append(np.mean(np.abs(np.mean(error_rates, axis=1))))\n",
    "    # et la variance des erreurs\n",
    "    mean_variance.append(np.mean(np.std(error_rates, axis=1)))\n",
    "    \n",
    "    one_tree = DecisionTreeRegressor(max_depth=depth).fit(x_train, y_train)\n",
    "    scores_one_tree.append(one_tree.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(max_depths, mean_bias)\n",
    "plt.title(u\"Évolution du biais en fonction de la profondeur des arbres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(max_depths, mean_variance)\n",
    "plt.title(u\"Évolution de la variance en fonction de la profondeur des arbres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(max_depths, scores_one_tree)\n",
    "plt.title(u\"Évolution du score d'un seul arbre en fonction de la profondeur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggrégation bootstrap (bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_bootstrap_aggregation_predictions = []\n",
    "# Pour chaque profondeur possible...\n",
    "for depth in max_depths:\n",
    "    # On va maintenant prédire la moyenne des prédictions des arbres\n",
    "    # entraînés sur les échantillons bootstrap\n",
    "    tree_samples = [train_individual_tree(sample, depth) for sample in samples]\n",
    "    predictions_tree_samples = [tree.predict(x_test) for tree in tree_samples]\n",
    "    bootstrap_aggregation_predictions = None\n",
    "    # TODO: prédire la moyenne des prédictions de chacun des arbres\n",
    "    score_bootstrap_aggregation_predictions.append(\n",
    "        r2_score(y_test, bootstrap_aggregation_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(max_depths, score_bootstrap_aggregation_predictions)\n",
    "plt.title(u\"Évolution de l'erreur de l'aggrégation bootstrap en fonction de la profondeur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualisons les prédictions pour des arbres de profondeur 10\n",
    "tree_samples = [train_individual_tree(sample, 10) for sample in samples]\n",
    "predictions_tree_samples = [tree.predict(x_test) for tree in tree_samples]\n",
    "bootstrap_aggregation_predictions = sum(predictions_tree_samples) / n_samples\n",
    "\n",
    "predictions_vs_realite_bootstrap_aggregation = pd.DataFrame({\"predictions sur ensemble de test\": bootstrap_aggregation_predictions,\n",
    "                                       \"valeurs ensemble de test\": y_test})\n",
    "predictions_vs_realite_bootstrap_aggregation.plot.scatter(x=\"predictions sur ensemble de test\", y=\"valeurs ensemble de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forêt d'arbres aléatoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](random_forest.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=50, n_estimators=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](boosting_trees.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = GradientBoostingRegressor(n_estimators=100, criterion=\"mse\")\n",
    "gbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: récupérer les données de départ, et remplacer les valeurs manquantes par la moyenne ou la médianne des valeurs de la colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO: Remplacer les colonnes contenant des variables catégorielles par des colonnes contenant des 0 et des 1, indicant si l'échangillon appartient ou non à la catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
